{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QKsx2j7w1f8L"
      },
      "source": [
        "# Project: Poetry generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rGhiI8Tm1pGo"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "# import string\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Conv1D, Flatten\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Wf47xVb8QpPN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Status:  200\n",
            "[INFO] Data have been downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    response = requests.get('https://raw.githubusercontent.com/laxmimerit/poetry-data/master/adele.txt')\n",
        "\n",
        "    print('Status: ', response.status_code)\n",
        "    print('[INFO] Data have been downloaded successfully')\n",
        "except Exception as e: \n",
        "    print('[ERROR] Data were not downloaded')\n",
        "    print(e)\n",
        "\n",
        "# In case the data cannot be downloaded, manually load file 'adele.txt' contained in directory Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FnC3zYN9UInx"
      },
      "outputs": [],
      "source": [
        "# Split text to lines\n",
        "data = response.text.splitlines()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SNPOGqKhU1F0"
      },
      "source": [
        "## Build LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LkVKR4ezDpwt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Vocabulary size:  1396\n"
          ]
        }
      ],
      "source": [
        "# Tokenization\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(data)\n",
        "\n",
        "# Encoded text\n",
        "encoded_text = token.texts_to_sequences(data)\n",
        "\n",
        "# Calculate vocabulary size\n",
        "vocab_size = len(token.word_counts) + 1\n",
        "print('[INFO] Vocabulary size: ', vocab_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T069CTTRXt_u"
      },
      "source": [
        "##  Prepare Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "colab_type": "code",
        "id": "teb0Ta9FDqSr",
        "outputId": "9c37ff60-411a-46af-d91a-98248a0d90dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Sequence length:  19\n"
          ]
        }
      ],
      "source": [
        "# Prepare training data\n",
        "datalist = []\n",
        "for d in encoded_text:\n",
        "  if len(d)>1:\n",
        "    for i in range(2, len(d)):\n",
        "      datalist.append(d[:i])\n",
        "      \n",
        "      \n",
        "# Padding\n",
        "max_length = 20\n",
        "sequences = pad_sequences(datalist, maxlen=max_length, padding='pre')\n",
        "\n",
        "\n",
        "# Create inputs/outputs\n",
        "X = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n",
        "\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "\n",
        "seq_length = X.shape[1]\n",
        "print('[INFO] Sequence length: ', seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZfHcmYz7bkG8"
      },
      "source": [
        "## LSTM Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "I0J_Jd4vDqo4"
      },
      "outputs": [],
      "source": [
        "# model = Sequential()\n",
        "# model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "# model.add(LSTM(100, return_sequences=True))\n",
        "# model.add(LSTM(100))\n",
        "# model.add(Dense(100, activation='relu'))\n",
        "# model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(Conv1D(64, activation='relu', kernel_size=4, strides=2, padding=\"same\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "MTvd-a_-Dq1N",
        "outputId": "e05509ff-237f-480c-e64b-85a69f778997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 5.6419 - accuracy: 0.0424\n",
            "Epoch 2/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 5.1054 - accuracy: 0.0661\n",
            "Epoch 3/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 4.6580 - accuracy: 0.1166\n",
            "Epoch 4/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 4.1836 - accuracy: 0.1838\n",
            "Epoch 5/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 3.7200 - accuracy: 0.2642\n",
            "Epoch 6/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 3.2932 - accuracy: 0.3357\n",
            "Epoch 7/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 2.9022 - accuracy: 0.3956\n",
            "Epoch 8/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 2.5618 - accuracy: 0.4515\n",
            "Epoch 9/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 2.2628 - accuracy: 0.5054\n",
            "Epoch 10/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 2.0123 - accuracy: 0.5456\n",
            "Epoch 11/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 1.8014 - accuracy: 0.5905\n",
            "Epoch 12/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 1.6189 - accuracy: 0.6233\n",
            "Epoch 13/100\n",
            "445/445 [==============================] - 2s 3ms/step - loss: 1.4661 - accuracy: 0.6552\n",
            "Epoch 14/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 1.3403 - accuracy: 0.6815\n",
            "Epoch 15/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 1.2264 - accuracy: 0.7047\n",
            "Epoch 16/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 1.1361 - accuracy: 0.7223\n",
            "Epoch 17/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 1.0582 - accuracy: 0.7385\n",
            "Epoch 18/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.9928 - accuracy: 0.7505\n",
            "Epoch 19/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.9344 - accuracy: 0.7642\n",
            "Epoch 20/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.8860 - accuracy: 0.7749\n",
            "Epoch 21/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.8444 - accuracy: 0.7825\n",
            "Epoch 22/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.8056 - accuracy: 0.7920\n",
            "Epoch 23/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.7774 - accuracy: 0.7966\n",
            "Epoch 24/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.7493 - accuracy: 0.8002\n",
            "Epoch 25/100\n",
            "445/445 [==============================] - 3s 6ms/step - loss: 0.7250 - accuracy: 0.8079\n",
            "Epoch 26/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.6979 - accuracy: 0.8129\n",
            "Epoch 27/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.6837 - accuracy: 0.8149\n",
            "Epoch 28/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.6689 - accuracy: 0.8163\n",
            "Epoch 29/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.6529 - accuracy: 0.8218\n",
            "Epoch 30/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.6409 - accuracy: 0.8239\n",
            "Epoch 31/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.6311 - accuracy: 0.8245\n",
            "Epoch 32/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.6182 - accuracy: 0.8260\n",
            "Epoch 33/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.6090 - accuracy: 0.8271\n",
            "Epoch 34/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.6006 - accuracy: 0.8297\n",
            "Epoch 35/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5915 - accuracy: 0.8317\n",
            "Epoch 36/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5862 - accuracy: 0.8359\n",
            "Epoch 37/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5791 - accuracy: 0.8315\n",
            "Epoch 38/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5727 - accuracy: 0.8326\n",
            "Epoch 39/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5773 - accuracy: 0.8334\n",
            "Epoch 40/100\n",
            "445/445 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.83 - 2s 4ms/step - loss: 0.5651 - accuracy: 0.8345\n",
            "Epoch 41/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5601 - accuracy: 0.8362\n",
            "Epoch 42/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5543 - accuracy: 0.8356\n",
            "Epoch 43/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5509 - accuracy: 0.8382\n",
            "Epoch 44/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5491 - accuracy: 0.8354\n",
            "Epoch 45/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5415 - accuracy: 0.8389\n",
            "Epoch 46/100\n",
            "445/445 [==============================] - 3s 6ms/step - loss: 0.5453 - accuracy: 0.8371\n",
            "Epoch 47/100\n",
            "445/445 [==============================] - 3s 7ms/step - loss: 0.5394 - accuracy: 0.8369\n",
            "Epoch 48/100\n",
            "445/445 [==============================] - 3s 6ms/step - loss: 0.5360 - accuracy: 0.8383\n",
            "Epoch 49/100\n",
            "445/445 [==============================] - 3s 6ms/step - loss: 0.5362 - accuracy: 0.8350\n",
            "Epoch 50/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.5292 - accuracy: 0.8385\n",
            "Epoch 51/100\n",
            "445/445 [==============================] - 2s 6ms/step - loss: 0.5281 - accuracy: 0.8385\n",
            "Epoch 52/100\n",
            "445/445 [==============================] - 2s 6ms/step - loss: 0.5292 - accuracy: 0.8377\n",
            "Epoch 53/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.5259 - accuracy: 0.8391\n",
            "Epoch 54/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.5189 - accuracy: 0.8418\n",
            "Epoch 55/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.5184 - accuracy: 0.8407\n",
            "Epoch 56/100\n",
            "445/445 [==============================] - 3s 6ms/step - loss: 0.5165 - accuracy: 0.8378\n",
            "Epoch 57/100\n",
            "445/445 [==============================] - 3s 6ms/step - loss: 0.5150 - accuracy: 0.8396\n",
            "Epoch 58/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.5134 - accuracy: 0.8414\n",
            "Epoch 59/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5120 - accuracy: 0.8387\n",
            "Epoch 60/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5135 - accuracy: 0.8410\n",
            "Epoch 61/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5092 - accuracy: 0.8406\n",
            "Epoch 62/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5082 - accuracy: 0.8389\n",
            "Epoch 63/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5010 - accuracy: 0.8431\n",
            "Epoch 64/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5045 - accuracy: 0.8391\n",
            "Epoch 65/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5019 - accuracy: 0.8411\n",
            "Epoch 66/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5017 - accuracy: 0.8399\n",
            "Epoch 67/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5014 - accuracy: 0.8409\n",
            "Epoch 68/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4985 - accuracy: 0.8432\n",
            "Epoch 69/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5030 - accuracy: 0.8419\n",
            "Epoch 70/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5003 - accuracy: 0.8400\n",
            "Epoch 71/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.5014 - accuracy: 0.8398\n",
            "Epoch 72/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.4974 - accuracy: 0.8401\n",
            "Epoch 73/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.4918 - accuracy: 0.8418\n",
            "Epoch 74/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.4933 - accuracy: 0.8403\n",
            "Epoch 75/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4890 - accuracy: 0.8403\n",
            "Epoch 76/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4887 - accuracy: 0.8413\n",
            "Epoch 77/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4871 - accuracy: 0.8406\n",
            "Epoch 78/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4894 - accuracy: 0.8414\n",
            "Epoch 79/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4895 - accuracy: 0.8423\n",
            "Epoch 80/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4897 - accuracy: 0.8414\n",
            "Epoch 81/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.4887 - accuracy: 0.8419\n",
            "Epoch 82/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4888 - accuracy: 0.8415\n",
            "Epoch 83/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4827 - accuracy: 0.8434\n",
            "Epoch 84/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4829 - accuracy: 0.8421\n",
            "Epoch 85/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4816 - accuracy: 0.8437\n",
            "Epoch 86/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4826 - accuracy: 0.8422\n",
            "Epoch 87/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4834 - accuracy: 0.8404\n",
            "Epoch 88/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4847 - accuracy: 0.8440\n",
            "Epoch 89/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4873 - accuracy: 0.8403\n",
            "Epoch 90/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4867 - accuracy: 0.8411\n",
            "Epoch 91/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.4773 - accuracy: 0.8429\n",
            "Epoch 92/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4770 - accuracy: 0.8448\n",
            "Epoch 93/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4715 - accuracy: 0.8440\n",
            "Epoch 94/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4729 - accuracy: 0.8446\n",
            "Epoch 95/100\n",
            "445/445 [==============================] - 2s 5ms/step - loss: 0.4729 - accuracy: 0.8428\n",
            "Epoch 96/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4726 - accuracy: 0.8450: 0s - loss: 0.4725 - accuracy: 0.\n",
            "Epoch 97/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4756 - accuracy: 0.8441\n",
            "Epoch 98/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4756 - accuracy: 0.8415\n",
            "Epoch 99/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4819 - accuracy: 0.8427\n",
            "Epoch 100/100\n",
            "445/445 [==============================] - 2s 4ms/step - loss: 0.4831 - accuracy: 0.8403\n"
          ]
        }
      ],
      "source": [
        "score = model.fit(X, y,\n",
        "                  batch_size=32, \n",
        "                  verbose=True, \n",
        "                  epochs=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nrOCcKYFeDPz"
      },
      "source": [
        "## Poetry Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "colab_type": "code",
        "id": "yv7kOw43Dq-f",
        "outputId": "abd8e395-68ae-4ffe-fada-87c958b7b3cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "when the rain is blowing in your right things i\n",
            "know it ain't easy giving up your mind some i'll\n",
            "be better to you let me stay here for just\n",
            "look and you will know i re love again i\n",
            "know it ain't easy giving up your mind some i'll\n"
          ]
        }
      ],
      "source": [
        "def generate_poetry(seed_text = '', n_lines = 5, poetry_length = 10):\n",
        "\n",
        "  for i in range(n_lines):\n",
        "    text = []\n",
        "    for _ in range(poetry_length):\n",
        "      encoded = token.texts_to_sequences([seed_text])\n",
        "      encoded = pad_sequences(encoded, maxlen=seq_length, padding='pre')\n",
        "\n",
        "      y_pred = np.argmax(model.predict(encoded), axis=-1)\n",
        "\n",
        "      predicted_word = \"\"\n",
        "      for word, index in token.word_index.items():\n",
        "        if index == y_pred:\n",
        "          predicted_word = word\n",
        "          break\n",
        "\n",
        "      seed_text = seed_text + ' ' + predicted_word\n",
        "      text.append(predicted_word)\n",
        "\n",
        "    seed_text = text[-1]\n",
        "    text = ' '.join(text)\n",
        "    print(text)\n",
        "\n",
        "\n",
        "    \n",
        "seed_text = 'i love you'\n",
        "generate_poetry(seed_text, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Poetry Generation Using Tensorflow, Keras and LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NLP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "24513103fde56bb2b83e620cc549278f11e79fde4f670db3dc95f99c43b58a75"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
