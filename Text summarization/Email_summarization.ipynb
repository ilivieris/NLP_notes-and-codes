{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module for E-mail Summarization\n",
    "*****************************************************************************\n",
    "Input Parameters:\n",
    "    emails: A list of strings containing the emails\n",
    "Returns:\n",
    "    summary: A list of strings containing the summaries.\n",
    "*****************************************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from talon.signature.bruteforce import extract_signature\n",
    "from langdetect import detect\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(email):\n",
    "    \"\"\"\n",
    "    Performs preprocessing operations such as:\n",
    "        1. Removing signature lines (only English emails are supported)\n",
    "        2. Removing new line characters.\n",
    "    \"\"\"\n",
    "    email, _ = extract_signature(email)\n",
    "    \n",
    "    lines = email.split('\\n')\n",
    "    for j in reversed(range(len(lines))):\n",
    "        lines[j] = lines[j].strip()\n",
    "        if lines[j] == '':\n",
    "            lines.pop(j)\n",
    "    \n",
    "    return ' '.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(email):\n",
    "    \"\"\"\n",
    "    Splits the emails into individual sentences\n",
    "    \"\"\"        \n",
    "    \n",
    "    sentences = sent_tokenize(email)\n",
    "    for j in reversed(range(len(sentences))):\n",
    "        sent = sentences[j]\n",
    "        sentences[j] = sent.strip()\n",
    "        if sent == '':\n",
    "            sentences.pop(j)\n",
    "        \n",
    "    return (sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoding(email, max_length=128):\n",
    "    \"\"\"\n",
    "    Obtains sentence embeddings for each sentence in the emails\n",
    "    \"\"\"\n",
    "    from transformers import BertTokenizer, BertForMaskedLM\n",
    "    import torch\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    inputs = tokenizer(email, return_tensors='pt', max_length=max_length, truncation=True, padding='max_length')   \n",
    "\n",
    "        \n",
    "    return inputs['input_ids'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization(processed_email_text:list = None, encoded_email_text:np.ndarray = None):\n",
    "    '''\n",
    "        Email summarization\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        processed_email_text: list with sentences composing the email \n",
    "        encoded_email_text:\n",
    "    '''\n",
    "\n",
    "    n_clusters = int(np.ceil(len(encoded_email_text)**0.5))\n",
    "    print('Number of clusters: ', n_clusters)\n",
    "\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans = kmeans.fit(encoded_email_text)\n",
    "    print('Kmeans trained')\n",
    "\n",
    "    avg = []\n",
    "    closest = []\n",
    "    for j in range(n_clusters):\n",
    "        idx = np.where(kmeans.labels_ == j)[0]\n",
    "        avg.append(np.mean(idx))\n",
    "    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, encoded_email_text)\n",
    "    ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "    \n",
    "    return ' '.join([processed_email_text[closest[idx]] for idx in ordering])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: cover_letter.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Ms. Lee,\n",
      "\n",
      "I'm writing to express my interest in the Web Content Manager position listed on CareerBuilder.com. \n",
      "I have experience building large, consumer-focused, health-based content sites. While much of my experience has been in the business world, I understand the social value of the non-profit sector and my business experience will be an asset to your organization.\n",
      "\n",
      "My responsibilities at my current job have included the development and management of the site’s editorial voice and style, the editorial calendar, and the daily content programming and production of the website. In my current and past positions, I have worked closely with health care professionals and medical editors to help them provide the best possible information to a consumer audience of patients. In addition, I have helped physicians learn to utilize their medical content to write user-friendly, readily comprehensible text.\n",
      "\n",
      "Experience has taught me how to build strong relationships with all departments at an organization. I have the ability to work within a team as well as across teams. I work with web engineers to resolve technical issues and implement technical enhancements, work with the development department to implement design and functional enhancements, and monitor site statistics and conduct search engine optimization. I know my work experience would make me an ideal Web Content Manager at your company.\n",
      "\n",
      "I am currently earning in the mid-sixties.\n",
      "\n",
      "Thank you for your consideration. I look forward to hearing from you.\n",
      "\n",
      "Kind regards,\n",
      "Alexandros Staikos\n"
     ]
    }
   ],
   "source": [
    "with open('Email_examples/cover_letter.txt') as f:\n",
    "    email_text = f.read()\n",
    "print(email_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email pre-processing...\n",
      "Splitting into sentences...\n",
      "Number of sentences:  13\n",
      "Encoding process...\n",
      "Number of clusters:  4\n",
      "Kmeans trained\n",
      "\n",
      "Summary:\n",
      " My responsibilities at my current job have included the development and management of the site’s editorial voice and style, the editorial calendar, and the daily content programming and production of the website. In addition, I have helped physicians learn to utilize their medical content to write user-friendly, readily comprehensible text. I have the ability to work within a team as well as across teams. I work with web engineers to resolve technical issues and implement technical enhancements, work with the development department to implement design and functional enhancements, and monitor site statistics and conduct search engine optimization.\n"
     ]
    }
   ],
   "source": [
    "print('Email pre-processing...')\n",
    "processed_email_text = preprocess(email_text)\n",
    "\n",
    "print('Splitting into sentences...')\n",
    "processed_email_text = split_sentences(processed_email_text)\n",
    "print('Number of sentences: ', len(processed_email_text))\n",
    "\n",
    "print('Encoding process...')\n",
    "encoded_email_text = Encoding(processed_email_text)    \n",
    "\n",
    "summary = summarization(processed_email_text, encoded_email_text)\n",
    "\n",
    "print('\\nSummary:\\n', summary)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: appreciating_the_customer.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good evening Mrs. Yoo,\n",
      "\n",
      "I'm reaching out on behalf of LettuceEat to thank you for your review of our restaurant on ReviewIt. \n",
      "We really appreciate your kind words and recommending our restaurant to others on the platform. \n",
      "\n",
      "LettuceEat is so happy you enjoyed our vegan options and your experience with us. \n",
      "\n",
      "\n",
      "Please come back soon!\n",
      "\n",
      "Best regards,\n",
      "Sarah Gibbs\n"
     ]
    }
   ],
   "source": [
    "with open('Email_examples/appreciating_the_customer.txt') as f:\n",
    "    email_text = f.read()\n",
    "print(email_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email pre-processing...\n",
      "Splitting into sentences...\n",
      "Number of sentences:  3\n",
      "Encoding process...\n",
      "Number of clusters:  2\n",
      "Kmeans trained\n",
      "\n",
      "Summary:\n",
      " Good evening Mrs. Yoo, I'm reaching out on behalf of LettuceEat to thank you for your review of our restaurant on ReviewIt. We really appreciate your kind words and recommending our restaurant to others on the platform.\n"
     ]
    }
   ],
   "source": [
    "print('Email pre-processing...')\n",
    "processed_email_text = preprocess(email_text)\n",
    "\n",
    "print('Splitting into sentences...')\n",
    "processed_email_text = split_sentences(processed_email_text)\n",
    "print('Number of sentences: ', len(processed_email_text))\n",
    "\n",
    "print('Encoding process...')\n",
    "encoded_email_text = Encoding(processed_email_text)    \n",
    "\n",
    "summary = summarization(processed_email_text, encoded_email_text)\n",
    "\n",
    "print('\\nSummary:\\n', summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Introducing_yourself.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning Mr. Sheehan,\n",
      "\n",
      "I would like to formally introduce myself. \n",
      "My name is Ethan and I am from Secure Shield, a company focused on protecting your home with security cameras and alarms.\n",
      "We understand the importance of keeping your family safe, and we want to ensure you have the best security system to meet your needs and budget. \n",
      "\n",
      "If you're interested in our services, please contact me at ccrenshaw@secureshield.com or call me at 555-555-5555. \n",
      "I'm looking forward to hearing from you!\n",
      "\n",
      "Best,\n",
      "Charles Crenshaw\n"
     ]
    }
   ],
   "source": [
    "with open('Email_examples/Introducing_yourself.txt') as f:\n",
    "    email_text = f.read()\n",
    "print(email_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email pre-processing...\n",
      "Splitting into sentences...\n",
      "Number of sentences:  4\n",
      "Encoding process...\n",
      "Number of clusters:  2\n",
      "Kmeans trained\n",
      "\n",
      "Summary:\n",
      " We understand the importance of keeping your family safe, and we want to ensure you have the best security system to meet your needs and budget. If you're interested in our services, please contact me at ccrenshaw@secureshield.com or call me at 555-555-5555.\n"
     ]
    }
   ],
   "source": [
    "print('Email pre-processing...')\n",
    "processed_email_text = preprocess(email_text)\n",
    "\n",
    "print('Splitting into sentences...')\n",
    "processed_email_text = split_sentences(processed_email_text)\n",
    "print('Number of sentences: ', len(processed_email_text))\n",
    "\n",
    "print('Encoding process...')\n",
    "encoded_email_text = Encoding(processed_email_text)    \n",
    "\n",
    "summary = summarization(processed_email_text, encoded_email_text)\n",
    "\n",
    "print('\\nSummary:\\n', summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24513103fde56bb2b83e620cc549278f11e79fde4f670db3dc95f99c43b58a75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
